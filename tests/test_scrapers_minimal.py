"""
Minimal scraper tests - validate that each Linux-compatible scraper can get real data.
These tests use minimal data requirements and are designed for CI environments.
"""

import pytest
from datetime import datetime, timedelta

from newswatch.api import scrape


# Linux-compatible scrapers (excluded ones that are known to fail on Linux/CI)
LINUX_SCRAPERS = [
    "antaranews",
    "bisnis", 
    "bloombergtechnoz",
    "cnbcindonesia",
    "detik",
    "kompas",
    # "metrotvnews",  # disabled: timeout issues in CI
    "okezone",
    "tempo",
    "viva",
    "mediaindonesia"
]


@pytest.mark.network
@pytest.mark.parametrize("scraper", LINUX_SCRAPERS)
def test_scraper_minimal_data(scraper):
    """Test that each scraper can get at least 1 article with minimal requirements."""
    
    # Use 7-day range to ensure content availability 
    week_ago = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
    
    try:
        # Use wider date range for reliable results
        articles = scrape(
            keywords="ekonomi",
            start_date=week_ago,
            scrapers=scraper,
            timeout=60  # 1 minute timeout per scraper
        )
        
        # Minimal validation - just check basic functionality
        assert len(articles) >= 1, f"{scraper} returned no articles with 'ekonomi' keyword in last 7 days"
        
        # Validate article structure
        article = articles[0]
        assert article.get('title'), f"{scraper} article missing title"
        assert article.get('content'), f"{scraper} article missing content"
        # Check source (might be 'kompas' or 'kompas.com' format)
        assert scraper in article.get('source', '').lower(), f"{scraper} not found in source: {article.get('source')}"
        assert article.get('link'), f"{scraper} article missing link"
        
        # Check that content has reasonable length (not empty or error message)
        assert len(article['content']) > 50, f"{scraper} content too short: {len(article['content'])} chars"
        assert len(article['title']) > 5, f"{scraper} title too short: {len(article['title'])} chars"
        
        print(f"âœ… {scraper}: {len(articles)} articles, title: '{article['title'][:50]}...'")
        
    except Exception as e:
        # Log the error but provide context about what we were testing
        pytest.fail(f"{scraper} scraper failed: {str(e)}")


